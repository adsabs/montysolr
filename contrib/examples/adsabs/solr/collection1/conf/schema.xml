<?xml version="1.0" encoding="UTF-8" ?>

<schema name="adsabs" version="1.5">

	<types>
		<fieldType name="string" class="solr.StrField"
			sortMissingLast="true" omitNorms="true" />
		<fieldType name="boolean" class="solr.BoolField"
			sortMissingLast="true" omitNorms="true" />
		<fieldType name="int" class="solr.TrieIntField"
			precisionStep="0" omitNorms="true" positionIncrementGap="0" />
		<fieldType name="float" class="solr.TrieFloatField"
			precisionStep="0" omitNorms="true" positionIncrementGap="0" />
		<fieldType name="long" class="solr.TrieLongField"
			precisionStep="0" omitNorms="true" positionIncrementGap="0" />
		<fieldType name="double" class="solr.TrieDoubleField"
			precisionStep="0" omitNorms="true" positionIncrementGap="0" />

		<fieldType name="tint" class="solr.TrieIntField"
			precisionStep="8" omitNorms="true" positionIncrementGap="0" />
		<fieldType name="tfloat" class="solr.TrieFloatField"
			precisionStep="8" omitNorms="true" positionIncrementGap="0" />
		<fieldType name="tlong" class="solr.TrieLongField"
			precisionStep="8" omitNorms="true" positionIncrementGap="0" />
		<fieldType name="tdouble" class="solr.TrieDoubleField"
			precisionStep="8" omitNorms="true" positionIncrementGap="0" />

		<fieldType name="date" class="solr.TrieDateField" omitNorms="true"
			precisionStep="0" positionIncrementGap="0" />
		<fieldType name="tdate" class="solr.TrieDateField"
			omitNorms="true" precisionStep="6" positionIncrementGap="0" />

		<fieldtype name="ignored" stored="false" indexed="false"
			multiValued="true" class="solr.StrField" />


		<!-- Author parsing section madness (START) -->

		<!-- Attention, all author_ types are very delicate! Always verify changes 
			with: TestAdsabsTypeAuthorParsing we have the following types: author author_notrans_nosyn 
			(public name: author_exact) author_notrans author_nosyn author_short_name_rage 
			(used only by query parser) author_collector (used only by dump-index component) -->

		<!-- The purpose of the collector is just to harvest the author transliterations, 
			we do it separately, not during the indexing (for speed/memory/control concerns) 
			testcase: TestBatchProviderDumpAuthorNames -->
		<fieldType name="author_collector" class="solr.TextField"
			positionIncrementGap="0">
			<analyzer type="query"> <!-- it must be query type!!! -->
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<filter class="solr.analysis.author.AuthorTransliterationFactory" />
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_INPUT,AUTHOR_TRANSLITERATED"
					emitTokens="true" />
			</analyzer>
		</fieldType>

		<fieldType name="author" class="solr.TextField"
			positionIncrementGap="0">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.TrimFilterFactory" />
				<filter
					class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />
			</analyzer>
			
			<!--  If you update the normalization components (ie. add new steps; especially
			      at the beginning, then you should also review the code inside:
			      AqpAdsabsExpandAuthorSearchProcessor.normalizeAuthorName()
			 -->
			       
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<!-- deal with natural order queries (this is used only at query time) -->
				<filter class="solr.analysis.author.PythonicAuthorNormalizeFilterFactory" />
				<!-- normalize order and surname form: eg. "adamcuk" becomes "adamcuk," 
					and "adamczuk, k" becomes "adamczuk, k" -->
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<!--  detect cases when we should bail-out and not attempt author search -->
				<filter class="solr.analysis.author.AuthorDetectAndIgnoreFilterFactory"
				   maxlen="5" />
				<!-- generate combinations to find their upgraded form -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="3" />
				<!-- add UTF-8 variant(s): "adamčuk, k" -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory" 
          synonyms="author_generated.translit"
          ignoreCase="true" 
          expand="true" 
          tokenizerFactory="solr.KeywordTokenizerFactory"
          builderFactory="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory$AlwaysIncludeOriginal"
          inclOrig="true" />
				<!-- now remove the query variants, they were used only to discover upgraded 
					forms -->
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_QUERY_VARIANT" emitTokens="false" />
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" />
				<!-- downgrade everything back to ascii (we now will have both ASCII 
					and UTF8 forms) -->
				<filter class="solr.analysis.author.AuthorTransliterationFactory"
					inputType="null" />
				<!-- generate ADS style extra search clauses (they will be used to find 
					synonyms): "adamcuk, piotr kolja" is expanded with: "adamcuk, piotr k" "adamcuk, 
					p kolja" "adamcuk, p k" "adamcuk," (if plainSurname=true) -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" />
				<!-- using any of the forms, find the synonyms, eg: "adamšuk, k", "adamčuk, 
					k", "adamguk, k" -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory" 
          synonyms="author_curated.synonyms" format="semicolon" 
					ignoreCase="true" expand="true" tokenizerFactory="solr.KeywordTokenizerFactory" />
				<!-- now remove the query variants, they were used only to discover synonyms -->
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_QUERY_VARIANT" emitTokens="false" />
				<!-- optionally: downgrade the newly found synonyms, so: "adamšuk, k" 
					is extended with" "adamshuk, k", "adamsuk, k" -->
				<filter class="solr.analysis.author.AuthorTransliterationFactory"
					inputType="SYNONYM" />
				<!-- lowercase normalize everything -->
				<filter class="solr.LowerCaseFilterFactory" />
				<!-- reset posIncrement - somtimes synonym expansion causes position 
					bumps but make sure we skip the first token -->
				<filter class="solr.analysis.ResetFilterFactory"
					posIncrement="0" range="1,100" />
				<!-- generate ADS style extra search clauses: "adamcuk, piotr kolja" 
					is extended with: "adamcuk, piotr k" "adamcuk, p kolja" "adamcuk, p k" "adamcuk, 
					p k *" "adamcuk, piotr k *" "adamcuk, p kolja *" "adamcuk," -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" plainSurname="true" addShortenedMultiName="true"
					addWildcards="false" lookAtPayloadForOrigAuthor="false" />
				<!-- deal with multiple occurences of the same (can happen because of 
					the overlapping synonyms) -->
				<filter
					class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />

			</analyzer>
		</fieldType>




		<!-- Author: transliteration NO, Synonym expansion YES -->

		<fieldType name="author_notrans" class="solr.TextField"
			positionIncrementGap="0">
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<!-- deal with natural order queries (this is used only at query time) -->
        <filter class="solr.analysis.author.PythonicAuthorNormalizeFilterFactory" />
				<!-- normalize order and surname form: eg. "adamcuk" becomes "adamcuk," 
					and "adamczuk, k" becomes "adamczuk, k" -->
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<!--  detect cases when we should bail-out and not attempt author search -->
        <filter class="solr.analysis.author.AuthorDetectAndIgnoreFilterFactory"
           maxlen="5" />
				<!-- generate ADS style extra search clauses (they will be used to find 
					synonyms): "adamcuk, piotr kolja" is expanded with: "adamcuk, piotr k" "adamcuk, 
					p kolja" "adamcuk, p k" "adamcuk," (if plainSurname=true) -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" />
				<!-- using any of the forms, find the synonyms, eg: "adamšuk, k", "adamčuk, 
					k", "adamguk, k" -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory" 
          synonyms="author_curated.synonyms" format="semicolon" 
          ignoreCase="true" expand="true" tokenizerFactory="solr.KeywordTokenizerFactory" />
				<!-- now remove the query variants, they were used only to discover synonyms -->
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_QUERY_VARIANT" emitTokens="false" />
				<!-- lowercase normalize everything -->
				<filter class="solr.LowerCaseFilterFactory" />
				<!-- reset posIncrement - somtimes synonym expansion causes position 
					bumps but make sure we skip the first token -->
				<filter class="solr.analysis.ResetFilterFactory"
					posIncrement="0" range="1,100" />
				<!-- generate ADS style extra search clauses: "adamcuk, piotr kolja" 
					is extended with: "adamcuk, piotr k" "adamcuk, p kolja" "adamcuk, p k" "adamcuk, 
					p k *" "adamcuk, piotr k *" "adamcuk, p kolja *" "adamcuk," -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" plainSurname="true" addShortenedMultiName="true"
					addWildcards="false" lookAtPayloadForOrigAuthor="false" />
				<!-- deal with multiple occurences of the same (can happen because of 
					the overlapping synonyms) -->
				<filter
					class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />

			</analyzer>
		</fieldType>


		<!-- Author: Transliteration YES, Synonym Expansion NO -->

		<fieldType name="author_nosyn" class="solr.TextField"
			positionIncrementGap="0">
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<!-- deal with natural order queries (this is used only at query time) -->
        <filter class="solr.analysis.author.PythonicAuthorNormalizeFilterFactory" />
				<!-- normalize order and surname form: eg. "adamcuk" becomes "adamcuk," 
					and "adamczuk, k" becomes "adamczuk, k" -->
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<!--  detect cases when we should bail-out and not attempt author search -->
        <filter class="solr.analysis.author.AuthorDetectAndIgnoreFilterFactory"
           maxlen="5" />
				<!-- generate combinations to find their upgraded form -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="3" />
				<!-- add UTF-8 variant(s): "adamčuk, k" -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory" 
          synonyms="author_generated.translit"
          ignoreCase="true" 
          expand="true" 
          tokenizerFactory="solr.KeywordTokenizerFactory"
          builderFactory="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory$AlwaysIncludeOriginal"
          inclOrig="true" />
				<!-- now remove the query variants, they were used only to discover upgraded 
					forms -->
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_QUERY_VARIANT" emitTokens="false" />
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" />
				<!-- downgrade everything back to ascii (we now will have both ASCII 
					and UTF8 forms) -->
				<filter class="solr.analysis.author.AuthorTransliterationFactory"
					inputType="null" />
				<!-- lowercase normalize everything -->
				<filter class="solr.LowerCaseFilterFactory" />
				<!-- reset posIncrement - somtimes synonym expansion causes position 
					bumps but make sure we skip the first token -->
				<filter class="solr.analysis.ResetFilterFactory"
					posIncrement="0" range="1,100" />
				<!-- generate ADS style extra search clauses: "adamcuk, piotr kolja" 
					is extended with: "adamcuk, piotr k" "adamcuk, p kolja" "adamcuk, p k" "adamcuk, 
					p k *" "adamcuk, piotr k *" "adamcuk, p kolja *" "adamcuk," -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" plainSurname="true" addShortenedMultiName="true"
					addWildcards="false" lookAtPayloadForOrigAuthor="false" />
				<!-- deal with multiple occurences of the same (can happen because of 
					the overlapping synonyms) -->
				<filter
					class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />
			</analyzer>
		</fieldType>


		<!-- Author: Transliteration NO, Synonym expansion NO -->

		<fieldType name="author_notrans_nosyn" class="solr.TextField"
			positionIncrementGap="0">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<filter class="solr.analysis.author.AuthorTransliterationFactory" />
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_TRANSLITERATED"
					emitTokens="false" />
				<filter class="solr.LowerCaseFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<!-- deal with natural order queries (this is used only at query time) -->
        <filter class="solr.analysis.author.PythonicAuthorNormalizeFilterFactory" />
				<!-- normalize order and surname form: eg. "adamcuk" becomes "adamcuk," 
					and "adamczuk, k" becomes "adamczuk, k" -->
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<!--  detect cases when we should bail-out and not attempt author search -->
        <filter class="solr.analysis.author.AuthorDetectAndIgnoreFilterFactory"
           maxlen="5" />
				<!-- generate combinations to find their upgraded form -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="3" />
				<!-- add UTF-8 variant(s): "adamčuk, k" -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory" 
          synonyms="author_generated.translit"
          ignoreCase="true" 
          expand="true" 
          tokenizerFactory="solr.KeywordTokenizerFactory"
          builderFactory="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory$AlwaysIncludeOriginal"
          inclOrig="true" />
				<!-- now remove the query variants, they were used only to discover upgraded 
					forms -->
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_QUERY_VARIANT" emitTokens="false" />
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" />
				<!-- downgrade everything back to ascii (we now will have both ASCII 
					and UTF8 forms) -->
				<filter class="solr.analysis.author.AuthorTransliterationFactory"
					inputType="null" />
				<!-- generate ADS style extra search clauses (they will be used to find 
					synonyms): "adamcuk, piotr kolja" is expanded with: "adamcuk, piotr k" "adamcuk, 
					p kolja" "adamcuk, p k" "adamcuk," (if plainSurname=true) -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" />
				<!-- using any of the forms, find the synonyms, eg: "adamšuk, k", "adamčuk, 
					k", "adamguk, k" -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory" 
          synonyms="author_curated.synonyms" format="semicolon" 
          ignoreCase="true" expand="true" tokenizerFactory="solr.KeywordTokenizerFactory" />
				<!-- now remove the query variants, they were used only to discover synonyms -->
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_QUERY_VARIANT" emitTokens="false" />
				<!-- optionally: downgrade the newly found synonyms, so: "adamšuk, k" 
					is extended with" "adamshuk, k", "adamsuk, k" -->
				<filter class="solr.analysis.author.AuthorTransliterationFactory"
					inputType="SYNONYM" />
				<!-- lowercase normalize everything -->
				<filter class="solr.LowerCaseFilterFactory" />
				<!-- reset posIncrement - somtimes synonym expansion causes position 
					bumps but make sure we skip the first token -->
				<filter class="solr.analysis.ResetFilterFactory"
					posIncrement="0" range="1,100" />
				<!-- generate ADS style extra search clauses: "adamcuk, piotr kolja" 
					is extended with: "adamcuk, piotr k" "adamcuk, p kolja" "adamcuk, p k" "adamcuk, 
					p k *" "adamcuk, piotr k *" "adamcuk, p kolja *" "adamcuk," -->
				<filter
					class="solr.analysis.author.AuthorCreateQueryVariationsFilterFactory"
					acronymVariations="1" plainSurname="true" addShortenedMultiName="true"
					addWildcards="false" lookAtPayloadForOrigAuthor="false" />
				<!-- deal with multiple occurences of the same (can happen because of 
					the overlapping synonyms) -->
				<filter
					class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />

			</analyzer>
		</fieldType>

		<!-- the following type is not used by any field, but it is used by the 
			query parser to upgrade the short author name "jones, c" into its long form 
			synonym "forman, christine" Believe me, you don't want to read about reasons 
			for doing it this way. -->
		<fieldType name="author_short_name_rage" class="solr.TextField">
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<!-- deal with natural order queries (this is used only at query time) -->
        <filter class="solr.analysis.author.PythonicAuthorNormalizeFilterFactory" />
				<filter class="solr.analysis.author.AuthorNormalizeFilterFactory" />
				<!-- if necessary, we will transliterate in order to match more synonyms -->
				<filter class="solr.analysis.author.AuthorTransliterationFactory" />
				<!-- we will use the standard synonym file (as used by the author type 
					above) but import it in a special way -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory"
          format="semicolon"
					synonyms="author_curated.synonyms" ignoreCase="true" expand="true"
					tokenizerFactory="solr.KeywordTokenizerFactory"
					builderFactory="org.apache.solr.analysis.author.AuthorShortNameUpgradeFilterFactory$MakeAllShortNames"
					inclOrig="true"/>
				<!-- remove the transliterated variants, they were used only to discover 
					synonyms -->
				<filter class="solr.analysis.author.AuthorCollectorFactory"
					tokenTypes="AUTHOR_TRANSLITERATED"
					emitTokens="false" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter
					class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />
			</analyzer>
		</fieldType>

		<!-- Author parsing section madness (STOP) -->






		<!-- Be careful, this chain is very 'delicate'! always run 
		     unittest: TestAdsabsTypeFulltext -->
		<!-- the tokenizing part needs more work, probably using synonyms to match 
			patterns? -->
		<fieldType name="ads_text" class="solr.TextField">
			<analyzer type="index">
        <charFilter class="solr.HTMLStripCharFilterFactory"/>
        
				<!-- AA: rewrite these common astronomy compound names so that the WDFF 
					will index both the short and long versions of them -->
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:(MESSIER)(-|\s+)([0-9]+[A-Z]*))\b" replacement="$1-$3 M$3" />
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:(ABELL)(-|\s+)([0-9]+[A-Z]*))\b" replacement="$1-$3 A$3" />
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:(N|NGC)(-|\s+)([0-9]+[A-Z]*))\b" replacement="NGC-$3" />
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:([34]CR?|ADS|H[DHR]|IC|[MW]|MKN|NGC|PKS|PSR[BJ]?|SAO|UGC|UT)(-|\s+)([0-9]+[A-Z]*))\b"
					replacement="$1-$3" />

				<!-- tokenize on empty space (if it is not a hyphen connecting other 
					words) -->
				<tokenizer class="solr.PatternTokenizerFactory" pattern="(?&lt;![-\s])\s+(?!-)"
					group="-1" />

				<!-- rca: i am not sure i understand, why isn't it: (\s*\-+\s*)+ and 
					the WDFF should be able to handle these cases anyway -->
				<filter class="solr.PatternReplaceFilterFactory" pattern="-?\s+-?"
					replacement="-" replace="all" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="^(\p{Punct}*)(.*?)(\p{Punct}*)$"
					replacement="$2" />

				<!-- split all-sky into [all, sky, allsky] -->
				<filter class="solr.WordDelimiterFilterFactory"
					generateWordParts="1" generateNumberParts="1" catenateWords="0"
					catenateNumbers="0" catenateAll="1" splitOnCaseChange="0"
					splitOnNumerics="0" stemEnglishPossessive="1" preserveOriginal="0" />

				<!-- lowercase everything besides ACRONYMS -->
				<filter
					class="org.apache.lucene.analysis.core.SelectiveLowerCaseFilterFactory" />


				<!-- find synonyms, first multi-tokens -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory"
					synonyms="ads_text_multi.synonyms" ignoreCase="false" expand="true"
					tokenizerFactory="solr.KeywordTokenizerFactory"
					builderFactory="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory$BestEffortIgnoreCaseSelectively"
					inclOrig="true" />

				<!-- now find simple synonyms (it may catch tokens that are part of the 
					multi-token synonym) -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory"
					synonyms="ads_text_simple.synonyms" ignoreCase="false" expand="true"
					tokenizerFactory="solr.KeywordTokenizerFactory"
					builderFactory="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory$BestEffortIgnoreCaseSelectively"
					inclOrig="true" />

				<!-- add a prefix to all synonyms -->
				<filter class="solr.analysis.ResetFilterFactory"
					incomingType="SYNONYM" addPrefix="syn::" posIncrement="0" />

				<!-- if the original or synonym contains UPPERCASE variant, mark it as 
					an acronym but keep the type information (if it is a synonym, it will remain 
					SYNONYM) which is important for the query parsing -->
				<filter class="solr.AcronymTokenFilterFactory" emitBoth="true"
					prefix="acr::" />

				<!-- remove stop words - first the case sensitively -->
				<filter class="solr.StopFilterFactory" ignoreCase="false"
					words="text.kill_sens" enablePositionIncrements="false" />
				<!-- remove stop words - then case insensitively -->
				<filter class="solr.StopFilterFactory" ignoreCase="true"
					words="text.kill" enablePositionIncrements="false" />



				<!-- we emit ASCIIField version of the token (at the same position): 
					this is rather crazy/expensive behaviour given that ads_text is used on fulltext, 
					can we get rid off it? -->
				<filter class="solr.ASCIIDuplicatingFilterFactory" />

				<!-- final normalization -->
				<filter class="solr.TrimFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
			</analyzer>
			<analyzer type="query">
        <charFilter class="solr.HTMLStripCharFilterFactory"/>
        
				<!-- AA: as above, but we only have one canonical replacement for the 
					expression -->
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:(MESSIER)(-|\s+)([0-9]+[A-Z]*))\b" replacement="M$3" />
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:(ABELL)(-|\s+)([0-9]+[A-Z]*))\b" replacement="A$3" />
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:(NGC|N)(-|\s+)([0-9]+[A-Z]*))\b" replacement="NGC$3" />
				<charFilter class="solr.PatternReplaceCharFilterFactory"
					pattern="\b(?i:([34]CR?|ADS|H[DHR]|IC|[MW]|MKN|NGC|PKS|PSR[BJ]?|SAO|UGC|UT)(-|\s+)([0-9]+[A-Z]*))\b"
					replacement="$1$3" />


				<!-- tokenize on empty space (if it is not a hyphen connecting other 
					words) -->
				<tokenizer class="solr.PatternTokenizerFactory" pattern="(?&lt;![-\s])\s+(?!-)"
					group="-1" />

				<filter class="solr.WordDelimiterFilterFactory"
					generateWordParts="1" generateNumberParts="1" catenateWords="0"
					catenateNumbers="0" catenateAll="1" splitOnCaseChange="0"
					splitOnNumerics="0" stemEnglishPossessive="1" preserveOriginal="0" />

				<!-- lowercase words, but keep ACRONYMS case ie. MOND => MOND Mond => 
					mond Hubble Space Telescope => hubble space telescope -->
				<filter
					class="org.apache.lucene.analysis.core.SelectiveLowerCaseFilterFactory" />

				<!-- search synonyms, first multi-tokens; includeOrig=true affects only 
					simple synonyms; for multi-tokens orig.parts are always returned. MOND = 
					MOND, modified newtonian dynamics hubble space telescope => HST [SYNONYM], 
					hubble space telescope [SYNONYM], hubble space telescope [original] Warning: 
					be sure you understand how inclOrig influences different types of synonym 
					rules ie. synonym1,synonym2 => synonym vs. synonym1,synonym2 -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory"
					synonyms="ads_text_multi.synonyms" ignoreCase="false" expand="true"
					tokenizerFactory="solr.KeywordTokenizerFactory"
					builderFactory="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory$BestEffortIgnoreCaseSelectively"
					inclOrig="true" />


				<!-- MOND => [] mond => mond, lunar [SYNONYM] hubble space telescope 
					=> HST [SYNONYM], hubble space telescope [SYNONYM], hubble, space, telescope 
					[original], spazio [SYNONYM] -->
				<filter class="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory"
					synonyms="ads_text_simple.synonyms" ignoreCase="false" expand="true"
					tokenizerFactory="solr.KeywordTokenizerFactory"
					builderFactory="org.apache.lucene.analysis.synonym.NewSynonymFilterFactory$BestEffortIgnoreCaseSelectively"
					inclOrig="true" />


				<!-- if the original or synonym contains UPPERCASE variant, mark it as 
					an acronym but do not change its type, if it was a SYNONYM, it is important 
					information for query parsing -->
				<filter class="solr.AcronymTokenFilterFactory" emitBoth="false"
					prefix="acr::" />

				<!-- add a prefix to all synonyms -->
				<filter class="solr.analysis.ResetFilterFactory"
					incomingType="SYNONYM" addPrefix="syn::" posIncrement="0" />

				<!-- remove stop words - first the case sensitively -->
				<filter class="solr.StopFilterFactory" ignoreCase="false"
					words="text.kill_sens" enablePositionIncrements="false" />
				<!-- remove stop words - then case insensitively -->
				<filter class="solr.StopFilterFactory" ignoreCase="true"
					words="text.kill" enablePositionIncrements="false" />



				<!-- we emit ASCIIField version of the token (at the same position) -->
				<filter class="solr.ASCIIDuplicatingFilterFactory" />

				<!-- final normalization -->
				<filter class="solr.TrimFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter
					class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />

				<!-- <filter class="solr.DiagnoseFilterFactory" /> -->
			</analyzer>
		</fieldType>


		<!-- AA: TODO: we should create a field type ads_text_nosyn to enable exact 
			searches RC: I think this must be subject to performance test given the troubles 
			we have experienced with speed degradation -->


		<!-- Type date_string is used for properly formatting (translating) the 
			Invenio and user input into the solr format. The real date is stored in the 
			field called 'date' and we require a properly formatted input to search there 
			unittest: TestAdsabsTypeDateString -->
			
			
		<fieldType name="date_string" class="solr.TextField"
			positionIncrementGap="0">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.DateNormalizerTokenFilterFactory" format="yyyy-MM-dd|yyyy-MM|yyyy" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.DateNormalizerTokenFilterFactory" format="yyyy-MM-dd|yyyy-MM|yyyy" />
			</analyzer>
		</fieldType>



		<fieldType name="doi_string" class="solr.TextField">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="doi:"
					replacement="" replace="all" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="doi:"
					replacement="" replace="all" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
		</fieldType>


		<!-- as opposed to doi_string, identifier is only ascii -->
		
		<fieldType name="identifier_normalized_string_ascii" class="solr.TextField">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(doi:|arxiv:)"
					replacement="" replace="all" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(doi:|arxiv:)"
					replacement="" replace="all" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
		</fieldType>


		<fieldType name="first_string" class="solr.TextField">
			<analyzer type="index">
				<tokenizer class="solr.PatternTokenizerFactory" pattern=";"
					group="-1" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(\-| )*([^- ,]+)(.*)"
					replacement="$2" replace="all" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.PatternTokenizerFactory" pattern=";"
					group="-1" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(\-| )*([^- ,]+)(.*)"
					replacement="$2" replace="all" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
		</fieldType>



		<!-- 
		  tokenized, normalized, emits only ASCII version, lowercased
		  test: TestAdsabsTypeNormalizedTextAscii
		 -->
		<fieldType name="normalized_text_ascii" class="solr.TextField">
			<analyzer type="index">
				<tokenizer class="solr.WhitespaceTokenizerFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(\-|_)"
          replacement="" replace="all" />
        <filter
          class="org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.WhitespaceTokenizerFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(\-|_)"
          replacement="" replace="all" />
			</analyzer>
		</fieldType>
		
		<!--copy of the chain above but without duplicates removal; this should be
		    used for situations where papers has multiple values per field; but we
		    want to keep them in order and not loss any. Example is author, which 
		    has its own affiliation and email
     -->
		<fieldType name="normalized_text_ascii_nodedup" class="solr.TextField">
      <analyzer type="index">
        <tokenizer class="solr.WhitespaceTokenizerFactory" />
        <filter class="solr.ASCIIFoldingFilterFactory" />
        <filter class="solr.LowerCaseFilterFactory" />
        <filter class="solr.PatternReplaceFilterFactory" pattern="(\-|_)"
          replacement="" replace="all" />
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.WhitespaceTokenizerFactory" />
        <filter class="solr.ASCIIFoldingFilterFactory" />
        <filter class="solr.LowerCaseFilterFactory" />
        <filter class="solr.PatternReplaceFilterFactory" pattern="(\-|_)"
          replacement="" replace="all" />
      </analyzer>
    </fieldType>

    <!-- 
      Normalize values, emit only ASCII version, lowercased.
      The difference from the previous is mainly in tokenization,
      essentially every value is indexed as a whole
      
      test: TestAdsabsTypeNormalizedStringAscii
     -->
     
		<fieldType name="normalized_string_ascii" class="solr.TextField">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(\-|_| )"
          replacement="" replace="all" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="(\-|_| )"
          replacement="" replace="all" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
		</fieldType>

		
    <!-- test: TestAdsabsTypeAffiliationText -->
    
		<fieldType name="affiliation_text" class="solr.TextField"
			positionIncrementGap="100">
			<analyzer type="index">
        <charFilter class="solr.HTMLStripCharFilterFactory"/>
        
        <!-- tokenize on empty space, comma, semicolon, brackets
         (but keep a hyphen connecting other  words) -->
        <tokenizer class="solr.PatternTokenizerFactory" pattern="(?&lt;![-\s])(\s|,|;|\(|\))+(?!-)"
          group="-1" />
          
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.WordDelimiterFilterFactory"
					generateWordParts="1" generateNumberParts="1" catenateWords="1"
					catenateNumbers="1" catenateAll="1" splitOnCaseChange="0"
					splitOnNumerics="1" stemEnglishPossessive="1" preserveOriginal="1" />
				<filter
					class="org.apache.lucene.analysis.core.SelectiveLowerCaseFilterFactory" />
				<filter class="solr.AcronymTokenFilterFactory" prefix="acr::"
					setType="ACRONYM" />
        <filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
			<analyzer type="query">
        <charFilter class="solr.HTMLStripCharFilterFactory"/>
				<!-- tokenize on empty space, comma, semicolon, brackets
         (but keep a hyphen connecting other  words) -->
        <tokenizer class="solr.PatternTokenizerFactory" pattern="(?&lt;![-\s])(\s|,|;|\(|\))+(?!-)"
          group="-1" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.WordDelimiterFilterFactory"
					generateWordParts="1" generateNumberParts="1" catenateWords="1"
					catenateNumbers="1" catenateAll="1" splitOnCaseChange="0"
					splitOnNumerics="1" stemEnglishPossessive="1" preserveOriginal="1" />
				<filter
					class="org.apache.lucene.analysis.core.SelectiveLowerCaseFilterFactory" />
				<filter class="solr.AcronymTokenFilterFactory" emitBoth="false"
					prefix="acr::" setType="ACRONYM" />
        <filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
		</fieldType>

		<!-- de-activated <similarity class="org.apache.solr.search.similarities.SweetSpotSimilarityFactory"> 
			<str name="min">1000</str> <str name="max">20000</str> <str name="steepness">0.5</str> 
			</similarity> </fieldType> -->





		<fieldType name="bibstem_facet" class="solr.TextField"
			sortMissingLast="true" omitNorms="true">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.TrimFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="^(\p{Punct}*)(.*?)(\p{Punct}*)$"
					replacement="$2" />
			</analyzer>
		</fieldType>

		<fieldType name="bibstem" class="solr.TextField"
			sortMissingLast="true" omitNorms="true">
			<analyzer type="index">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.TrimFilterFactory" />
			</analyzer>
			<analyzer type="query">
				<tokenizer class="solr.KeywordTokenizerFactory" />
				<filter class="solr.LowerCaseFilterFactory" />
				<filter class="solr.ASCIIFoldingFilterFactory" />
				<filter class="solr.TrimFilterFactory" />
				<filter class="solr.PatternReplaceFilterFactory" pattern="^(.*?)(\.*)$"
					replacement="$1" />
				<!-- note: do not use BibstemFF in the query phase, we cannot assume 
					the input has bibcode form -->
			</analyzer>
		</fieldType>



	</types>

	<fields>
	
	  <!-- conventions: all field names are ascii, we have several special fields
	                    they are all identified through their suffix
	                    
	                    used by query parser to analyze a field when a specific
	                    query is built
	                    
	                    <field>_wildcard 
	                    <field>_fuzzy
	                    <field>_regex
	                    
	                    Usually, these are only safe to use with the simple types,
	                    such as normalized_string_ascii. You can't hope to get
	                    a meaningful results if you try to use ads_text for example.
	                    Besided, these fields should produce ONLY one token (1 in,
	                    1 out)
	   -->

		
			
		<!-- 
		@api.doc
		
		* id
		
		  Text field with unique string; ID of the document.
		  
		    Example query:
		    
		      id:5
		  
		* recid
		
		  Integer version of 'id' - this is more efficient for sorting,
		  and range queries
		  
			  Example query:
	        
	        id:5
		  
	  * bibcode
	  
	    19-char long string (unique) - ADS identifier of a paper
	    
	       Example query:
        
           bibcode:1902Sci....15..393S
		 -->
		 
		 <!-- The uniqueKey index must be implemented using StrField therefore we 
      cannot use bibcode (and have it lowercased). And for the same reasons, we 
      cannot have recid to be int. We are getting an error: QueryElevationComponent 
      requires the schema to have a uniqueKeyField implemented using StrField -->
      
		<field name="id" type="string" indexed="true" stored="true" multiValued="false"
			required="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		<field name="recid" type="int" indexed="true" stored="true" multiValued="false"
			required="false" omitNorms="true" omitTermFreqAndPositions="true"/>
		<field name="bibcode" type="normalized_string_ascii" indexed="true" multiValued="false"
			stored="true" required="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		
		<!-- 
		@api.doc
		
		* doi
		
		  Digital object indentifier
		  
		* identifier
		
		  Identifier under which a paper can be found. This index holds values 
		  from several other fields:
		    
		    - bibcode
		    - doi
		    - alternate_bibcode
		  
		    
		* alternate_bibcode
		
		  When a paper is published, we may decide to assign a new bibcode to the
		  old version of metatada. The alternate_bibcode can be used for queries
		  that need to find it using the old (once-known) bibcode.
		  
		  This field is also useful for citation cache, because reference values
		  (bibcodes) may contain old bibcodes.
		  
		  
		* bibstem
		
		  Bibstems identify publication or publication and volume.
		  
		  Example query:
		  
		    bibstem:Sci
        bibstem:Sci.....6
		  
		* bibstem_facet
		
		  Technical field, used for faceting by publication. It contains only 
		  bibstems without volumes (eg. Sci)
		  
		 -->	

		<field name="doi" type="doi_string" indexed="true" stored="true"
			multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		

		<field name="identifier" type="identifier_normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="alternate_bibcode" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>

		<field name="bibstem" type="bibstem" indexed="true" stored="${storeAll:false}"
			multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
      
		<field name="bibstem_facet" type="bibstem_facet" indexed="true"
			stored="${storeAll:false}" omitNorms="true" omitTermFreqAndPositions="true"/>


    
    <!-- 
    @api.doc
    
    * pub
    
      Publication
      
    * pub_raw
    
      Full string from the "Journal field" of the ADS Record
      
    * page
    
      String value (possibly two) indicating page range. Not all values are
      numeric!
      
    * year
    
      Year when the paper was published (warning, not all values are numeric)
      
    * volume
    
      Volume of a journal issue (if any) of the paper.
      
    * issue
    
      Issue number in which a paper was published.
      
    * issn
    
      ISSN of the publication (applies to journals - ie. periodical publications)
          
    * isbn
    
      ISBN of the publication (this applies to books)
      
    * lang
      
      In ADS this field contains a language of the main title. Currently, this value
      is present in a very small portion of records (try searching for lang:*) 
      
      
     -->
		<field name="pub" type="normalized_text_ascii" indexed="true" stored="true" 
		  omitNorms="true" />
      
		<field name="pub_raw" type="normalized_text_ascii" indexed="true"	stored="true" 
		  omitNorms="true" />

		<field name="page" type="first_string" indexed="true" stored="true"
			multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="year" type="first_string" indexed="true" stored="true" 
			multiValued="false" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="volume" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="false" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="issue" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="false" omitNorms="true" omitTermFreqAndPositions="true"/>

		<field name="issn" type="normalized_string_ascii" indexed="true" stored="true"  
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="isbn" type="normalized_string_ascii" indexed="true" stored="true"
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		
		<field name="lang" type="normalized_string_ascii" indexed="true" stored="${storeAll:false}"
			omitNorms="true" omitTermFreqAndPositions="true"/>


		<!-- We get pubdate from invenio, we turn that into a properly formatted 
			date string and insert that into 'date' field (the DIH transformer does that) -->
			
		<field name="date" type="tdate" indexed="true" stored="${storeAll:false}"
			omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="pubdate" type="date_string" indexed="true" stored="true"
			omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="pubdate_sort" type="int" indexed="true" stored="${storeAll:false}"
			omitNorms="true" omitTermFreqAndPositions="true"/>


		<field name="title" type="ads_text" indexed="true" stored="true" 
      multiValued="true" termVectors="true" termOffsets="true" 
      termPositions="true"/>
            
		<field name="alternate_title" type="ads_text" indexed="true" stored="true" 
		  multiValued="true" termVectors="true" />

		<field name="abstract" type="ads_text" indexed="true" stored="true"
			termVectors="true" termOffsets="true" termPositions="true" />



		<field name="author" type="author" indexed="true" stored="true"
			multiValued="true" omitNorms="true"/>
			
		<field name="author_norm" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true"/>
			
		<field name="author_facet" type="string" indexed="true" stored="${storeAll:false}" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="author_facet_hier" type="string" indexed="true" stored="${storeAll:false}" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="first_author_facet_hier" type="string" indexed="true" stored="${storeAll:false}" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>

		<field name="first_author" type="author" indexed="true" stored="true" />
		
		<field name="first_author_norm" type="normalized_string_ascii"
			indexed="true" stored="true" />
		
		<field name="aff" type="affiliation_text" indexed="true" stored="true"
			multiValued="true" omitNorms="true"/>
			
		<field name="email" type="normalized_text_ascii" indexed="true" stored="true"
			multiValued="true" omitNorms="true"/>

    <!-- 
    @api.doc
    
    * keyword
    
      Free-text keywords; this field also contains arxiv_class values.
      This field ignores 
      
    * keyword_norm
    
      Controlled keywords, each entry will have a corresponding keyword_schema
      value.
      
    * keyword_schema
    
      Schema for each controlled keyword.
      
      @since 40.4.0.0
      
    * keyword_facet
    
      This is the normalized version of a controlled keyword (if paper contains it).
      Very often this value may be missing.
     -->
		<field name="keyword" type="normalized_text_ascii" indexed="true"
			stored="true" multiValued="true" omitNorms="true"/>
			
		<field name="keyword_norm" type="normalized_text_ascii_nodedup" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true"/>
			
		<field name="keyword_schema" type="normalized_text_ascii_nodedup" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true"/>
      
    <field name="keyword_facet" type="string" indexed="true" stored="true"
      multiValued="true" omitNorms="true"/>
      
    <field name="arxiv_class" type="normalized_text_ascii" indexed="true" stored="true"
      multiValued="true" omitNorms="true"/>
      
        

		<field name="property" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="database" type="normalized_string_ascii" indexed="true" stored="true"
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="bibgroup" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="bibgroup_facet" type="string" indexed="true"	stored="${storeAll:false}" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="data" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="data_facet" type="string" indexed="true"	stored="${storeAll:false}" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="vizier" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="vizier_facet" type="string" indexed="true"	stored="${storeAll:false}" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="thesis" type="affiliation_text" indexed="true"	stored="true" 
		  omitNorms="true" />
		  
		<field name="comment" type="string" indexed="true" stored="${storeAll:false}" 
		  omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="copyright" type="affiliation_text" indexed="true" stored="true" 
		  omitNorms="true" />

		<field name="reference" type="normalized_string_ascii" indexed="true" stored="true" 
		  multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
      
	  <field name="citation" type="normalized_string_ascii" indexed="true" stored="true" 
      multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
      		
		<field name="facility" type="normalized_text_ascii" indexed="true" stored="true"
      multiValued="true" omitNorms="true"/>
			
		
			
	  <!-- 
	  @api.doc
	  
	  * grant 
	     
	     Field that contains both grant ids and grant agencies.
	     
	     @since 40.3.0.0
	  
	  * grant_facet_hier
	  
	     Hiearchical facet field which containst grant/grant_id.
	     This field is not suitable for user queries, but rather
	     for UI components. Term frequencies and positions are
	     deactivated.
	     
	  * grant_id
	  
	     Index with just the grant ids (e.g. 0618398). 
	     
	     @depracated - use grant instead
	     
	  * grant_agencies
    
       Index with just the grant agencies names (e.g. NASA). 
       
       @depracated - use grant instead
	   -->
	  <field name="grant" type="normalized_text_ascii" indexed="true" stored="true"
      multiValued="true" omitNorms="true"/> 
      
		<field name="grant_facet_hier" type="string" indexed="true"
			stored="true" multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>

    
    <!-- 
    @api.doc
    
    * all
    
      This index contains values copied from several other fields (the fields
      are added into one index for faster search). These values come from:
      
       - author_norm
       - alternate_title
       - bibcode
       - doi
       - identifier 
    
    -->
		<field name="all" type="ads_text" indexed="true" stored="false"
			multiValued="true" />




		<!-- 
		@api.doc
		
		* full
		
		  This is a virtual field, it doesn't have its own index, but 
		  searches several other indexes
		  
		  @since 40.3.0.0 
		  
		* body
		
		  Contains extracted fulltext minus acknowledgements section
		  
		  @since 40.3.0.0 
		  
		* ack
		
		  Contains acknowledgements extracted from fulltexts (if it was
		  possible to identify them).
		  
		 -->
		<field name="full" type="ads_text" indexed="false" stored="false"/>
      
		<field name="body" type="ads_text" indexed="true" stored="true"
			termVectors="true" termOffsets="true" termPositions="true" />
			
		<field name="ack" type="ads_text" indexed="true" stored="true" />
		
		
		<!-- 
		@api.doc
		
		* reader
		
		  This index contains unique identifiers of readers that read the
		  paper in the past 90 days. This field does not have term frequncies
		  and positions.
		  
		 -->
		<field name="reader" type="string" indexed="true" stored="true"
			multiValued="true" omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<!-- 
    @api.doc
    
    * cite_read_boost
    
      Float values containing normalized (float) boost factors. These
      can be used with functional queries to modify ranking of results. 
      
      Example:
      
        q={!func}product(product(0.5,$scaledQ),product(0.5,field('cite_read_boost')))
        qq={!aqp}black hole
        fq={!query v=$qq}
        
      @since 40.2.0.0
        
    * classic_factor
    
      Integer values containing the boost factor used by ADS Classic. In essence
      log(1 + cites + norm_reads) where number of citations has been normalized
      and the whole value is multiplied by 5000 and then cast to Integer.
      
      @since 40.3.0.0 
      
     -->
		<field name="cite_read_boost" type="tfloat" indexed="true" stored="true" 
		  omitNorms="true" omitTermFreqAndPositions="true"/>
			
		<field name="classic_factor" type="int" indexed="true" stored="true" 
		  omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="simbid" type="int" indexed="true" stored="true" multiValued="true"
		  omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="citation_count" type="int" indexed="true" stored="true" 
		  omitNorms="true" omitTermFreqAndPositions="true"/>
		  
		<field name="read_count" type="tfloat" indexed="true" stored="true" 
		  omitNorms="true" omitTermFreqAndPositions="true"/>

		<!-- 
		  technical metadata; values are a JSON string that is stored and used for search result 
			display 
			-->
		<field name="links_data" type="string" indexed="false" stored="true"
			multiValued="true" />
			
		<field name="ids_data" type="string" indexed="false" stored="true"
			multiValued="true" />


    <!-- 
    @api.doc
    
    * indexstamp
    
      Each document contains a date when it was indexed. The format
      is: YYYY-MM-DD'T'hh:mm:ss.SSS'Z' - ie. you can query with up to
      millisecond granularity; note that your query string must be
      complete and correct 
      
      Example query:
        
         indexstamp:[2013-03-04T22:01:32.809Z TO *]
         
     -->
		<field name="indexstamp" type="date" indexed="true" stored="true"
			default="NOW" multiValued="false" />
			
    <field name="_version_" type="long" indexed="true" stored="true" />
    

		<!-- uncomment the following to ignore any fields that don't already match 
			an existing field name or dynamic field, rather than reporting them as an 
			error. alternately, change the type="ignored" to some other type e.g. "text" 
			if you want unknown fields indexed and/or stored by default -->
		<dynamicField name="tmp_*" type="ignored" multiValued="true" />


		
		<!-- 
		=================================================
		collector fields, used just for indexing
		=================================================
		 -->
		
    <field name="a_100" type="author" indexed="false" stored="false"
            multiValued="true" />
    <field name="a_700" type="author" indexed="false" stored="false"
            multiValued="true" />
    <field name="a_100_norm" type="author" indexed="false" stored="false"
            multiValued="true" />
    <field name="a_700_norm" type="author" indexed="false" stored="false"
            multiValued="true" />

		<!-- 
		=================================================
		fields used for special purposes by query parser 
		=================================================
		-->
		
		<field name="bibcode_wildcard" type="normalized_string_ascii" 
      indexed="false" stored="false" required="false" multiValued="false" />
    
    <field name="doi_wildcard" type="doi_string"
      indexed="false" stored="false" required="false" multiValued="true" />
        
    <field name="pub_wildcard" type="normalized_text_ascii" 
      indexed="false" stored="false" required="false" multiValued="false" />
    
    <field name="issn_wildcard" type="normalized_string_ascii" 
      indexed="false" stored="false" multiValued="false"/>
    
    <field name="isbn_wildcard" type="normalized_string_ascii" 
      indexed="false" stored="false" required="false" multiValued="false" />
          
		<field name="author_notrans" type="author_short_name_rage"
			indexed="false" stored="false" />
			
		<field name="author_nosyn" type="author_short_name_rage"
			indexed="false" stored="false" />
			
		<field name="author_notrans_nosyn" type="author_short_name_rage"
			indexed="false" stored="false" />
			
		<field name="author_short_name_rage" type="author_short_name_rage"
			indexed="false" stored="false" />

    <field name="author_collector" type="author_collector" 
      indexed="false" stored="false" multiValued="true" />
    
    <field name="reference_wildcard" type="normalized_string_ascii" 
      indexed="false" stored="false" required="false" />  
        
		<!-- a field holding tokenizer chain for the unfield search (very important 
			to have if you require multi-word token expansion and unfielded search expansion 
			at the same time -->
			
		<field name="unfielded_search" type="ads_text"
			indexed="false" stored="false" multiValued="true" />

	</fields>

	<uniqueKey>id</uniqueKey>

	<!-- field for the QueryParser to use when an explicit fieldname is absent -->
	<defaultSearchField>all</defaultSearchField>

	<!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
	<solrQueryParser defaultOperator="AND" />

	<copyField source="id" dest="recid" />

  <copyField source="arxiv_class" dest="keyword" />
	<copyField source="keyword_norm" dest="keyword" />
	
	<copyField source="bibgroup" dest="bibgroup_facet" />
	<copyField source="data" dest="data_facet" />
	<copyField source="vizier" dest="vizier_facet" />

	<copyField source="a_100" dest="author" />
	<copyField source="a_700" dest="author" />

	<copyField source="a_100_norm" dest="author_norm" />
	<copyField source="a_700_norm" dest="author_norm" />

	<copyField source="a_100_norm" dest="author_facet" />
	<copyField source="a_700_norm" dest="author_facet" />

	<copyField source="a_100" dest="first_author" />
	<copyField source="a_100_norm" dest="first_author_norm" />

  <copyField source="tmp_aff_100" dest="aff" />
  <copyField source="tmp_aff_700" dest="aff" />
  
  <copyField source="tmp_email_100" dest="email" />
  <copyField source="tmp_email_700" dest="email" />
  
  
  <copyField source="bibcode" dest="identifier" />
  <copyField source="alternate_bibcode" dest="identifier" />
  <copyField source="doi" dest="identifier" />
  
	<copyField source="author_norm" dest="all" />
	<copyField source="alternate_title" dest="all" />
	<copyField source="bibcode" dest="all" />
	<copyField source="doi" dest="all" />
	<copyField source="identifier" dest="all" />
  
  <copyField source="alternate_title" dest="title" />	

</schema>

